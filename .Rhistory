nh <- subset(df, df$Region == "New Hampshire")
nh$GG/nh$GB
print(Ratio is 1 GG to 2 GB)
print("Ratio is 1 GG to 2 GB")
print ("Question 5")
nh <- subset(df, df$Region == "New Hampshire")
nh$GG/nh$GB
nrow(gg_10)/nrow(df)*100
print ("Question 5")
nh <- subset(df, df$Region == "New Hampshire")
4
nh <- subset(df, df$Region == "New Hampshire")
nh$GG/nh$GB
print("Ratio is 1 GG to 2 GB")
## Question 1
df <-read.csv(file = 'C:/Users/HP/Documents/688/Data/geoMap.csv')
less_1 <- subset(df, df$GG == "<1")
less_1$Region
df[df == "<1"] <- "0"
df
boy <-subset(df, (df$GB > df$GG))
boy
nrow(boy)
df$GG <- as.numeric(as.character(df$GG))
df$GB <- as.numeric(as.character(df$GB))
df$GG_10 <- df$GG + 10
gg_10 <- subset(df, df$GB < df$GG_10)
gg_10$Region
nrow(gg_10)/nrow(df)*100
print ("Question 5")
nh <- subset(df, df$Region == "New Hampshire")
nh$GG/nh$GB
print("Ratio is 1 GG to 2 GB")
#Question 6
counts <- table(mtcars$vs, mtcars$gear)
barplot(counts, main="Car Distribution by Gears and VS",
xlab="Number of Gears", col=c("darkblue","red"),
legend = rownames(counts), beside=TRUE)
counts <- table(df$GG, df$GB)
barplot(counts, main="Presents",
xlab="States", col=c("darkblue","red"),
legend = rownames(counts), beside=TRUE)
barplot(counts, main="Presents",
xlab="States", col=c("darkblue","red"),
legend = rownames(GG, GB), beside=TRUE)
counts <- table(df$Region, df$GB)
barplot(counts, main="Presents",
xlab="States", col=c("darkblue","red"),
legend = rownames("GG", "GB"), beside=TRUE)
#Question 6
table(df$Region)
#Question 6
table(df$Region, df$GB)
#Question 6
table(df$Region, df$GB, df$GG)
#Question 6
barplot(df$Region)
#Question 6
barplot(df$Region)
barplot(counts, main="Presnets",
xlab="States", col=c("darkblue","red"),
legend = rownames(df$Region), beside=TRUE)
barplot(counts, main="Presents",
xlab="States", col=c("darkblue","red"),
legend = rownames(df$Region), beside=TRUE)
counts
barplot(df$GB, main="Presents",
barplot(table(df$GB), main="Presents",
barplot(table(df$GG), main="Presents",
legend = rownames(df$Region), beside=TRUE
barplot(df$GG, main="Presents",
xlab="States", col=c("darkblue","red"),
legend = rownames(df$Region), beside=TRUE
xlab="States", col=c("darkblue","red")
barplot(df$GG, main="Presents",
xlab="States" col=c("darkblue","red")
legend = rownames(df$Region), beside=TRUE
barplot(df$GB,names.arg=df$Region,xlab="States",ylab="Presents",
col="blue",
main="Presents",border="red")
barplot(df$GG,names.arg=df$Region,xlab="States",ylab="Presents",
col="blue",
main="Presents",border="red")
nh$GG/nh$GB
barplot(df)
df
df$GG_10 <- Null
df$GG_10 <- NULL
df
barplot(df)
library(ggplot2)
table(df)
table(df$Region, df$GB)
table(df$GB,(df$Region))
barplot(table(df$GB,(df$Region)))
barplot(vec2, vec3)
vec1 <- df$Region
vec2 <- df$GB
barplot(vec2, vec3)
vec3 <- df$GG
barplot(vec2, vec3)
legend("topleft",
c("GB","GG"),
fill = c("red","blue")
barplot(vec2, vec3)
legend("topleft",
c("GB","GG"),
fill = c("red","blue")
barplot(vec2, vec3
main = "Presents",
xlab = "States",
col = c("red","blue")
)
legend("topleft",
c("GB","GG"),
fill = c("red","blue")
)
barplot(vec2, vec3,
main = "Presents",
xlab = "States",
col = c("red","blue")
)
legend("topleft",
c("GB","GG"),
fill = c("red","blue")
)
legend("topright",
c("GB","GG"),
fill = c("red","blue")
)
barplot(vec2, vec3,
main = "Presents",
xlab = "States",
col = c("red","blue")
)
legend("topright",
c("GB","GG"),
fill = c("red","blue")
barplot(vec2, vec3,
main = "Presents",
xlab = "States",
col = c("red","blue")
)
legend("topright",
c("GB","GG"),
fill = c("red","blue")
)
barplot(vec2, vec3,
main = "Presents",
xlab = "States",
names.arg = vec1,
col = c("red","blue")
)
legend("topright",
c("GB","GG"),
fill = c("red","blue")
)
legend("top",
c("GB","GG"),
fill = c("red","blue")
)
barplot(vec2, vec3,
main = "Presents",
xlab = "States",
names.arg = vec1,
col = c("red","blue")
)
legend("top",
c("GB","GG"),
fill = c("red","blue")
)
barplot(vec2, vec3,
main = "Presents",
xlab = "States",
names.arg = vec1,
col = c("red","blue")
)
legend("bottom",
c("GB","GG"),
fill = c("red","blue")
)
legend("bottomright",
c("GB","GG"),
fill = c("red","blue")
)
barplot(vec2, vec3,
main = "Presents",
xlab = "States",
names.arg = vec1,
col = c("red","blue")
)
legend("bottomright",
c("GB","GG"),
fill = c("red","blue")
)
#Question 6
library("ggplot2")
geom_blank()
library("ggplot2")
geom_blank()
vec1 <- df$Region
vec2 <- df$GB
vec3 <- df$GG
barplot(vec2, vec3,
main = "Presents",
xlab = "States",
names.arg = vec1,
col = c("red","blue")
)
legend("bottomright",
c("GB","GG"),
fill = c("red","blue")
)
barplot(vec2, vec3,
main = "Presents",
xlab = "States",
ylab - " # of presents"
names.arg = vec1,
col = c("red","blue")
)
legend("bottomright",
c("GB","GG"),
fill = c("red","blue")
)
barplot(vec2, vec3,
main = "Presents",
xlab = "States",
ylab - "# of presents"
names.arg = vec1,
col = c("red","blue")
)
legend("bottomright",
c("GB","GG"),
fill = c("red","blue")
)
barplot(vec2, vec3,
main = "Presents",
xlab = "States",
ylab - "# of presents"
names.arg = vec1,
col = c("red","blue")
)
legend("bottomright",
c("GB","GG"),
fill = c("red","blue")
)
barplot(vec2, vec3,
main = "Presents",
xlab = "States",
ylab - "# of presents",
names.arg = vec1,
col = c("red","blue")
)
legend("bottomright",
c("GB","GG"),
fill = c("red","blue")
)
library("ggplot2")
geom_blank()
vec1 <- df$Region
vec2 <- df$GB
vec3 <- df$GG
barplot(vec2, vec3,
main = "Presents",
xlab = "States",
ylab - "# of presents",
names.arg = vec1,
col = c("red","blue")
)
legend("bottomright",
c("GB","GG"),
fill = c("red","blue")
)
vec1 <- df$Region
vec2 <- df$GB
vec3 <- df$GG
barplot(vec2, vec3,
main = "Presents",
xlab = "States",
names.arg = vec1,
col = c("red","blue")
)
legend("bottomright",
c("GB","GG"),
fill = c("red","blue")
)
library(tm)
detach("package:tm", unload = TRUE)
library(tm)
# Text Mining Exercises
rm(list=ls()); cat("\014") # Clear Workspace and Console
library(tm) # Load the Text Mining package
### ====== Example ====
# Example R Script: Extracting text content from text files and load them as Corpus
loremipsum <- system.file("texts", "loremipsum.txt", package = "tm") # Path to "loremipsum.txt"
ovid <- system.file("texts", "txt", "ovid_1.txt", package = "tm") # Path to "ovid.txt"
Docs.pth <- URISource(sprintf("file://%s", c(loremipsum, ovid))) # Specify Source
corpus.txt<-VCorpus(Docs.pth) # load them as Corpus
inspect(corpus.txt)
inspect(corpus.txt)
rm(list=ls()); cat("\014") # Clear Workspace and Console
library(tm) # Load the Text Mining package
library(tm) # Load the Text Mining package
library(tm) # Load the Text Mining package
### ====== Example ====
# Example R Script: Extracting text content from text files and load them as Corpus
loremipsum <- system.file("texts", "loremipsum.txt", package = "tm") # Path to "loremipsum.txt"
loremipsum <- system.file("texts", "loremipsum.txt", package = "tm")
loremipsum <- system.file("texts", "loremipsum.txt", package = "tm")
rm(list=ls()); cat("\014") # Clear Workspace and Console
library(tm) # Load the Text Mining package
library(NLP)
library(tm) # Load the Text Mining package
loremipsum <- system.file("texts", "loremipsum.txt", package = "tm") # Path to "loremipsum.txt"
rm(list=ls()); cat("\014") # Clear Workspace and Console
library(NLP)
library(tm) # Load the Text Mining package
### ====== Example ====
# Example R Script: Extracting text content from text files and load them as Corpus
loremipsum <- system.file("texts", "loremipsum.txt", package = "tm") # Path to "loremipsum.txt"
loremipsum
ovid
ovid <- system.file("texts", "txt", "ovid_1.txt", package = "tm") # Path to "ovid.txt"
### ====== Example ====
# Example R Script: Extracting text content from text files and load them as Corpus
loremipsum <- system.file("texts", "loremipsum.txt", package = "tm") # Path to "loremipsum.txt"
ovid
# Example: Shiny app that search Wikipedia web pages
# File: WikiSearch.R
# Wikipedia Search
library(tm)
library(stringi)
library(WikipediR)
# library(proxy)
titles <- c("Web_analytics","Text_mining","Integral", "Calculus",
"Lists_of_integrals", "Derivative","Alternating_series",
"Pablo_Picasso","Vincent_van_Gogh","Lev_Tolstoj","Web_crawler")
SearchWiki <- function (titles) {
# wiki.URL <- "https://en.wikipedia.org/wiki/"
# articles <- lapply(titles,function(i) stri_flatten(readLines(stri_paste(wiki.URL,i)), col = " "))
articles <- lapply(titles,function(i) page_content("en","wikipedia", page_name = i,as_wikitext=TRUE)$parse$wikitext)
docs <- Corpus(VectorSource(articles)) # Get Web Pages' Corpus
remove(articles)
# Text analysis - Preprocessing
transform.words <- content_transformer(function(x, from, to) gsub(from, to, x))
temp <- tm_map(docs, transform.words, "<.+?>", " ")
temp <- tm_map(temp, transform.words, "\t", " ")
temp <- tm_map(temp, content_transformer(tolower)) # Conversion to Lowercase
# temp <- tm_map(temp, PlainTextDocument)
temp <- tm_map(temp, stripWhitespace)
temp <- tm_map(temp, removeWords, stopwords("english"))
temp <- tm_map(temp, removePunctuation)
temp <- tm_map(temp, stemDocument, language = "english") # Perform Stemming
remove(docs)
# Create Dtm
dtm <- DocumentTermMatrix(temp)
dtm <- removeSparseTerms(dtm, 0.4)
dtm$dimnames$Docs <- titles
docsdissim <- dist(as.matrix(dtm), method = "euclidean") # Distance Measure
h <- hclust(as.dist(docsdissim), method = "ward.D2") # Group Results
}
reuters <- VCorpus(DirSource(reut21578), readerControl = list(reader = readReut21578XMLasPlain))
library(tm)
reut21578 <- system.file("texts", "acq", package = "tm") #
reuters <- VCorpus(DirSource(reut21578), readerControl = list(reader = readReut21578XMLasPlain))
View(reuters)
reuters[14]
library(tm)
reut21578 <- system.file("texts", "acq", package = "tm") #
reuters <- VCorpus(DirSource(reut21578), readerControl = list(reader = readReut21578XMLasPlain))
reuters[14]
reuters[14]
# Analyze MLD GS Language Detection
rm(list=ls()); cat("\014") # Clear Workspace and Console
library("cld2"); library("cld3")
library("readr"); library("magrittr")
# 1) Your Code HERE: Load the file names that need to be processed into "files.txt"
#files.txt <- load.files(path="data/sentence data", all.files = FALSE, full.names = FALSE)
files.txt <- list.files(path = "Data/sentence data")
files.txt
Result.DF <- data.frame()
for (ff in 1:length(files.txt)) {
fn <- files.txt[ff]
txt.data <- read_tsv(fn)
Lg.Data.Code <- cld2::detect_language(txt.data[[1]]) # Get Language Code
Lg.Data.Lg <- cld2::detect_language(txt.data[[1]], lang_code = FALSE) # Get Language
Lg.Data.Code <- Lg.Data.Code[!is.na(Lg.Data.Code)]; Lg.Data.Lg <- Lg.Data.Lg[!is.na(Lg.Data.Lg)]  # Remove NA From Language Code & Language
Predicted.Lg.Code <- names(sort(table(Lg.Data.Code), decreasing=TRUE)[1]) # Find Dominant Language Code
Predicted.Lg <- names(sort(table(Lg.Data.Lg), decreasing=TRUE)[1]) # Find Dominant Language
# 2) Your Code HERE: Extract the language 2 letter code from the file name ()
GT.Lg <- sub(".*_","", files.txt )
GT.Lg <- sub(".txt.*", "", GT.Lg) # Extract the ground truth Language code from the file name (i.e. get "ar" from "sentence_ar.txt")
Correct <- GT.Lg == Predicted.Lg.Code
temp1 <- data.frame(GS_Lg_Code=GT.Lg, Pred_Lg_Code=Predicted.Lg.Code, Correct=Correct, Pred_Lg=Predicted.Lg, stringsAsFactors = FALSE)
Result.DF <- rbind(Result.DF, temp1)
}
knitr::kable(Result.DF) # Display result of Language Detection
# Analyze MLD GS Language Detection
rm(list=ls()); cat("\014") # Clear Workspace and Console
library("cld2"); library("cld3")
library("readr"); library("magrittr")
# 1) Your Code HERE: Load the file names that need to be processed into "files.txt"
#files.txt <- load.files(path="data/sentence data", all.files = FALSE, full.names = FALSE)
files.txt <- list.files(path = "Data/sentence data")
files.txt
files.txt
Forecast.Electric.Demand <- function (Raw_Data)
{
print("2. Inputs sent to function: Forecast.Electric.Demand()")
# Extract Time Stemps from Data
Num.Data.Points <- dim(Raw_Data)[1]
Time.Stamp <- strptime(Raw_Data$DATE,"%m/%d/%Y %H:%M")
# Select Training Range
StartTime <- 1 # which(Time.Stamp=="2014-03-01 01:00:00 EST")
TrainRange <- StartTime:Num.Data.Points
print(paste0("Training data start date: ",Time.Stamp[StartTime]))
# Extract Hours field from Time.Stamp
#  Hours <- rep(1,length(TrainRange)) # Replace this Line
# Insert your code here
Hours <- as.numeric(format(Time.Stamp,'%H'))
# Extract Days field from Time.Stamp
# Day.Number <- rep(1,length(TrainRange)) # Replace this Line
# Insert your code here
Day.Date <- as.numeric(format(Time.Stamp,'%d'))
Day.Number <- as.numeric(format(Time.Stamp,'%w'))
Day.Number[Day.Number==0] = 7
Day.Name <- weekdays(Time.Stamp)
#Hours.Modified <- Hours # Replace this Line
#Day.Number.Modified <- Day.Number # Replace this Line
# Insert your code here
temp <- 12 - Hours; temp[temp >= 0] = 0
Hours.Modified <- Hours + 2*temp
Day.Number.Modified <- Day.Number
Day.Number.Modified[Day.Number <6] =1];
delay.dat.houston <- read.csv("./Datasets/HoustonAirline.csv",
header=TRUE,
stringsAsFactors = FALSE)
library(dplyr)
delay.dat.houston <- read.csv("./Datasets/HoustonAirline.csv",
header=TRUE,
stringsAsFactors = FALSE)
library(dplyr)
delay.dat.houston <- read.csv("./Datasets/HoustonAirline.csv",
header=TRUE,
stringsAsFactors = FALSE)
library(dplyr)
delay.dat.houston <- read.csv("./Datasets/HoustonAirline.csv",
header=TRUE,
stringsAsFactors = FALSE)
library(dplyr)
delay.dat.houston <- read.csv("./Datasets/HoustonAirline.csv",
header=TRUE,
stringsAsFactors = FALSE)
delay.dat.houston <- read.csv("./Datasets/HoustonAirline.csv",
header=TRUE,
stringsAsFactors = FALSE)
delay.dat.houston <- read.csv("./Datasets/HairEyeColor.csv",
header=TRUE,
stringsAsFactors = FALSE)
library(help = "datasets")
data()
rm(list=ls()); cat("\014")
#Set directory
setwd("C:/Users/HP/Documents/555")
getwd()
#1
#Import spreadsheet
student = read.csv("student.csv", header = TRUE)
as.data.frame(student)
is.factor(student$group)
student$group = factor(student$group)
is.factor(student$group)
attach(student)
summary(as.factor(student$group))
summary(age)
library(ggplot2)
library(dplyr)
grp_tbl <- student %>% group_by(group)
grp_tbl
age_tbl <- grp_tbl %>% summarise(mean(age))
age_tbl
iq_tbl <- grp_tbl %>% summarise(mean(iq))
iq_tbl
boxplot(iq ~ group, main="IQ", xlab="group", ylab="iq")
boxplot(age ~ group, main="Age", xlab="group", ylab="age")
ggplot(student, aes(age,iq, colour = group)) +
geom_point()
#f critical value
qf(.95,2,42)
m<- aov(iq~group)
summary(m)
anova(m)
#Tukey
TukeyHSD(m)
#3
Physics <- ifelse(student$group=='Physics', 1, 0)
Math <- ifelse(student$group=='Math', 1, 0)
Chemistry <- ifelse(student$group=='Chemistry', 1, 0)
m2 <- lm(iq ~ Physics+ Math, data=student)
summary(m2)
anova(m2)
install.packages("car")
library(car)
Anova(lm(iq ~ group + age), type=3)
my.model<-lm(iq~group+age,  data = student)
emm_options(contrasts=c("contr.treatment", "contr.poly"))
emmeans(my.model, specs = "group")
# Least square means
install.packages("emmeans")
library(emmeans)
# Least square means
install.packages("emmeans")
